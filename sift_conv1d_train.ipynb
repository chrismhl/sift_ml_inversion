{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f1082e",
   "metadata": {},
   "source": [
    "# Train and Test 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ca53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sift_conv1dnet as sconv\n",
    "import sift_conv1dnet_nat as sconv_n\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a1304",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0da9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time window\n",
    "twin = 45\n",
    "\n",
    "# Load fq data\n",
    "npyd = 'npy'\n",
    "eta = np.load(os.path.join(npyd,'fq_dart_eta.npy'))\n",
    "t = np.load(os.path.join(npyd,'fq_dart_time.npy'))\n",
    "\n",
    "# Load inversions\n",
    "fq_wts = np.load(os.path.join(npyd,'fq_yong_inv_best.npy'))\n",
    "\n",
    "# Split into train and test sets\n",
    "inddir = 'indices'\n",
    "\n",
    "train_ind = np.loadtxt(os.path.join(inddir,'fq_dart_train_index.txt')).astype(int)\n",
    "train_runs= np.loadtxt(os.path.join(inddir,'fq_dart_train_runs.txt')).astype(int)\n",
    "\n",
    "test_ind = np.loadtxt(os.path.join(inddir,'fq_dart_test_index.txt')).astype(int)\n",
    "test_runs= np.loadtxt(os.path.join(inddir,'fq_dart_test_runs.txt')).astype(int)\n",
    "\n",
    "valid_ind = np.loadtxt(os.path.join(inddir,'fq_dart_valid_index.txt')).astype(int)\n",
    "valid_runs= np.loadtxt(os.path.join(inddir,'fq_dart_valid_runs.txt')).astype(int)\n",
    "\n",
    "eta_tr = eta[train_ind, :, :twin]\n",
    "t_tr = t[train_ind, :, :twin]\n",
    "target_tr = fq_wts[train_ind,:]\n",
    "\n",
    "eta_ts = eta[test_ind, :, :twin]\n",
    "t_ts = t[test_ind, :, :twin]\n",
    "target_ts = fq_wts[test_ind,:]\n",
    "\n",
    "eta_v = eta[valid_ind, :, :twin]\n",
    "t_v = t[valid_ind, :, :twin]\n",
    "target_v = fq_wts[valid_ind,:]\n",
    "\n",
    "# Convert to tensors. Will need to redo if i want to keep track of run numbers...\n",
    "\n",
    "batch = 20\n",
    "shuf = False\n",
    "\n",
    "train_x = torch.Tensor(eta_tr)\n",
    "train_y = torch.Tensor(target_tr)\n",
    "\n",
    "test_x = torch.Tensor(eta_ts)\n",
    "test_y = torch.Tensor(target_ts)\n",
    "\n",
    "valid_x = torch.Tensor(eta_v)\n",
    "valid_y = torch.Tensor(target_v)\n",
    "\n",
    "# Using the pytorch dataloader\n",
    "train_dataset = TensorDataset(train_x,train_y)\n",
    "test_dataset = TensorDataset(test_x,test_y)\n",
    "valid_dataset = TensorDataset(valid_x,valid_y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch, shuffle = shuf, drop_last= True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch, shuffle = shuf, drop_last= True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch, shuffle = shuf, drop_last= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e9431",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26704c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    valid_model = model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = valid_model(X)\n",
    "            \n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "    valid_loss /= size\n",
    "    \n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Specify model, loss function, and optimizer.\n",
    "\n",
    "nsources = 31 # Number of unit sources used in inversion\n",
    "model = sconv.Conv1DNN(3, nsources).to(device)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3943635",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "nbatches = len(train_dataloader)\n",
    "train_loss_array = np.zeros(epochs)\n",
    "valid_loss_array = np.zeros(epochs)\n",
    "\n",
    "for t in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_func(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of training loss\n",
    "        train_loss += loss.item()\n",
    "        avg_train_loss = train_loss/nbatches\n",
    "        \n",
    "        # Comment this out when u dont need it anymore. \n",
    "        avg_valid_loss = valid(valid_dataloader, model, loss_func)\n",
    "        model.train(True) #Do i need this?\n",
    "        \n",
    "    # every 50 epochs, print test error    \n",
    "    if (t+1) % 50 == 0:\n",
    "        print('Epoch: %s' % str(t+1))\n",
    "        print('------')\n",
    "        print(f\"Avg Train loss: {avg_train_loss:>8f} \\n\")\n",
    "        print(f\"Avg Validation loss: {avg_valid_loss:>8f} \\n\")\n",
    "    \n",
    "    train_loss_array[t] = avg_train_loss\n",
    "    valid_loss_array[t] = avg_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ff1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_array, label='Train Loss')\n",
    "plt.plot(valid_loss_array, label='Valid. Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Avg MSE Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012911c",
   "metadata": {},
   "source": [
    "## Output results for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict test data.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_test = model(test_x)\n",
    "    print(loss_func(pred_test,test_y).item())\n",
    "\n",
    "# Output as .npy array\n",
    "#np.save(os.path.join(npyd,'fq_conv_wts_300.npy'), pred_test.detach().numpy())\n",
    "\n",
    "# Or alternatively output as a .csv file\n",
    "# np.savetxt(os.path.join(npyd,'fq_conv_wts_300_nat.csv'),pred_test.detach().numpy(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17012d98",
   "metadata": {},
   "source": [
    "# Output the model\n",
    "See https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ea0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model = model(pre_trained=True)\n",
    "# torch.save(save_model.state_dict(), 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
