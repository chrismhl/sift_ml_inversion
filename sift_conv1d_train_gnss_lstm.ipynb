{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6030ae",
   "metadata": {},
   "source": [
    "# Train and Test 1D Convolutional Neural Network for GNSS using RNN\n",
    "\n",
    "Author: Christopher Liu, 11/14/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a32a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sift_conv1dnet as sconv\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f18b06",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de8252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dart names\n",
    "in_fpath = 'sift_ml_input.csv'\n",
    "if os.path.isfile(in_fpath):\n",
    "     ml_input = pd.read_csv(in_fpath, dtype = {'unit_sources': str, 'dart': str,\\\n",
    "                                             'lat_d': np.float64, 'long_d': np.float64,\\\n",
    "                                             'extra_forecast': str, 'lat_f': np.float64,\\\n",
    "                                             'long_f': np.float64})\n",
    "else:\n",
    "    sys.exit(\"Error: Unit source file cannot be found.\")\n",
    "dart = ml_input['dart'][ml_input.dart.notnull()].tolist()\n",
    "\n",
    "# Load fq data\n",
    "npyd = 'npy'\n",
    "eta = np.load(os.path.join(npyd,'gnss_eta_all.npy'))\n",
    "\n",
    "# load unit source TS\n",
    "dfd = 'unit_src_ts'\n",
    "eta_us = np.zeros((1440,3,31))\n",
    "for n, name in enumerate(dart):\n",
    "    eta_us[:,n,:] = pd.read_csv(os.path.join(dfd,'eta_%s.csv' % name))\n",
    "\n",
    "# Load inversions (weights and ts)\n",
    "fq_wts = np.load(os.path.join(npyd,'fq_yong_inv_best.npy'))\n",
    "fq_ts = np.load(os.path.join(npyd,'fq_wt_eta.npy'))\n",
    "\n",
    "# Split into train, validation,  and test sets\n",
    "inddir = 'indices'\n",
    "\n",
    "train_ind = np.loadtxt(os.path.join(inddir,'fq_dart_train_index.txt')).astype(int)\n",
    "train_runs= np.loadtxt(os.path.join(inddir,'fq_dart_train_runs.txt')).astype(int)\n",
    "\n",
    "test_ind = np.loadtxt(os.path.join(inddir,'fq_dart_test_index.txt')).astype(int)\n",
    "test_runs= np.loadtxt(os.path.join(inddir,'fq_dart_test_runs.txt')).astype(int)\n",
    "\n",
    "valid_ind = np.loadtxt(os.path.join(inddir,'fq_dart_valid_index.txt')).astype(int)\n",
    "valid_runs= np.loadtxt(os.path.join(inddir,'fq_dart_valid_runs.txt')).astype(int)\n",
    "\n",
    "eta_tr = np.swapaxes(eta[train_runs, :, :],1,2)\n",
    "# target_tr = fq_ts[train_ind,:,:360]\n",
    "target_tr = fq_wts[train_ind,:]\n",
    "\n",
    "eta_ts = np.swapaxes(eta[test_runs, :, :],1,2)\n",
    "# target_ts = fq_ts[test_ind,:,:360]\n",
    "target_ts = fq_wts[test_ind,:]\n",
    "\n",
    "eta_v = np.swapaxes(eta[valid_runs, :, :],1,2)\n",
    "# target_v = fq_ts[valid_ind,:,:360]1\n",
    "target_v = fq_wts[valid_ind,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f033956-1beb-4425-8927-10de350de754",
   "metadata": {},
   "source": [
    "## Scale Data and Load Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4dafefe-454c-4943-ac0d-d4e6be09c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors. Will need to redo if i want to keep track of run numbers...\n",
    "batch = 20\n",
    "shuf = False\n",
    "scale = True\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "if scale:\n",
    "    train_x = torch.Tensor(scaler.fit_transform(eta_tr.reshape(-1, eta_tr.shape[-1])).reshape(eta_tr.shape)).cuda()\n",
    "    test_x = torch.Tensor(scaler.transform(eta_ts.reshape(-1, eta_ts.shape[-1])).reshape(eta_ts.shape)).cuda()\n",
    "    valid_x = torch.Tensor(scaler.transform(eta_v.reshape(-1, eta_v.shape[-1])).reshape(eta_v.shape)).cuda()\n",
    "else:   \n",
    "    train_x = torch.Tensor(eta_tr).cuda()\n",
    "    test_x = torch.Tensor(eta_ts).cuda()\n",
    "    valid_x = torch.Tensor(eta_v).cuda()\n",
    "\n",
    "train_y = torch.Tensor(target_tr).cuda()\n",
    "test_y = torch.Tensor(target_ts).cuda()\n",
    "valid_y = torch.Tensor(target_v).cuda()\n",
    "\n",
    "us_tn = torch.Tensor(eta_us[:360,:,:]).cuda()\n",
    "\n",
    "# Using the pytorch dataloader\n",
    "train_dataset = TensorDataset(train_x,train_y)\n",
    "test_dataset = TensorDataset(test_x,test_y)\n",
    "valid_dataset = TensorDataset(valid_x,valid_y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch, shuffle = shuf, drop_last= True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch, shuffle = shuf, drop_last= True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch, shuffle = shuf, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c38cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    plt.figure(1,figsize=(12,6))\n",
    "    for r in np.arange(62):\n",
    "        plt.plot(np.arange(512), eta_ts[100,r,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc15f58",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420df81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(dataloader, model, loss_fn):\n",
    "    size = len(dataloader) # number of batches\n",
    "    valid_model = model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = valid_model(X)\n",
    "            \n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "    valid_loss /= size\n",
    "    \n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06cdb097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Set Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Set random seed\n",
    "torch.random.manual_seed(100) #for ae/de, optimizer gets stuck for seed = 100\n",
    "\n",
    "# Specify model, loss function, and optimizer.\n",
    "\n",
    "nsources = 31 # Number of unit sources used in inversion\n",
    "model = sconv.Conv1DNN_GNSS_RNN(62*3, nsources, 5, 128, us_tn).to(device)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb2818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\n",
      "------\n",
      "Avg Train loss: 44.556522 \n",
      "\n",
      "Avg Train loss w/ eval: 44.396184 \n",
      "\n",
      "Avg Validation loss: 41.147537 \n",
      "\n",
      "Avg Test loss: 37.516287 \n",
      "\n",
      "Epoch: 50\n",
      "------\n",
      "Avg Train loss: 44.529735 \n",
      "\n",
      "Avg Train loss w/ eval: 44.394681 \n",
      "\n",
      "Avg Validation loss: 41.140118 \n",
      "\n",
      "Avg Test loss: 37.498160 \n",
      "\n",
      "Epoch: 75\n",
      "------\n",
      "Avg Train loss: 30.716856 \n",
      "\n",
      "Avg Train loss w/ eval: 30.738219 \n",
      "\n",
      "Avg Validation loss: 31.869185 \n",
      "\n",
      "Avg Test loss: 29.341451 \n",
      "\n",
      "Epoch: 100\n",
      "------\n",
      "Avg Train loss: 26.454847 \n",
      "\n",
      "Avg Train loss w/ eval: 27.312397 \n",
      "\n",
      "Avg Validation loss: 26.050387 \n",
      "\n",
      "Avg Test loss: 26.302601 \n",
      "\n",
      "Epoch: 125\n",
      "------\n",
      "Avg Train loss: 24.207828 \n",
      "\n",
      "Avg Train loss w/ eval: 23.761765 \n",
      "\n",
      "Avg Validation loss: 24.032049 \n",
      "\n",
      "Avg Test loss: 23.526025 \n",
      "\n",
      "Epoch: 150\n",
      "------\n",
      "Avg Train loss: 23.129676 \n",
      "\n",
      "Avg Train loss w/ eval: 22.991162 \n",
      "\n",
      "Avg Validation loss: 24.606351 \n",
      "\n",
      "Avg Test loss: 23.207116 \n",
      "\n",
      "Epoch: 175\n",
      "------\n",
      "Avg Train loss: 22.840455 \n",
      "\n",
      "Avg Train loss w/ eval: 22.850827 \n",
      "\n",
      "Avg Validation loss: 24.692442 \n",
      "\n",
      "Avg Test loss: 22.985175 \n",
      "\n",
      "Epoch: 200\n",
      "------\n",
      "Avg Train loss: 22.041293 \n",
      "\n",
      "Avg Train loss w/ eval: 21.893579 \n",
      "\n",
      "Avg Validation loss: 24.144467 \n",
      "\n",
      "Avg Test loss: 22.723364 \n",
      "\n",
      "Epoch: 225\n",
      "------\n",
      "Avg Train loss: 20.988613 \n",
      "\n",
      "Avg Train loss w/ eval: 24.014139 \n",
      "\n",
      "Avg Validation loss: 27.618597 \n",
      "\n",
      "Avg Test loss: 24.942701 \n",
      "\n",
      "Epoch: 250\n",
      "------\n",
      "Avg Train loss: 20.070241 \n",
      "\n",
      "Avg Train loss w/ eval: 27.423499 \n",
      "\n",
      "Avg Validation loss: 30.487414 \n",
      "\n",
      "Avg Test loss: 28.381422 \n",
      "\n",
      "Epoch: 275\n",
      "------\n",
      "Avg Train loss: 18.839863 \n",
      "\n",
      "Avg Train loss w/ eval: 27.518106 \n",
      "\n",
      "Avg Validation loss: 30.805021 \n",
      "\n",
      "Avg Test loss: 29.195515 \n",
      "\n",
      "Epoch: 300\n",
      "------\n",
      "Avg Train loss: 18.762733 \n",
      "\n",
      "Avg Train loss w/ eval: 28.266843 \n",
      "\n",
      "Avg Validation loss: 32.258676 \n",
      "\n",
      "Avg Test loss: 30.180560 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "nbatches = len(train_dataloader)\n",
    "train_loss_array = np.zeros(epochs)\n",
    "test_loss_array = np.zeros(epochs)\n",
    "valid_loss_array = np.zeros(epochs)\n",
    "\n",
    "for t in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_func(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of training loss\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Calculating the batch-averaged loss\n",
    "    avg_train_loss = train_loss/nbatches\n",
    "    avg_train_loss_nbn = valid(train_dataloader, model, loss_func)\n",
    "    avg_valid_loss = valid(valid_dataloader, model, loss_func)\n",
    "    avg_test_loss = valid(test_dataloader, model, loss_func)\n",
    "    model.train(True) #Do i need this?\n",
    "        \n",
    "    # every 50 epochs, print test error. Adjust print frequency \n",
    "    # depending on epoch size\n",
    "    if (t+1) % 25 == 0:\n",
    "        print('Epoch: %s' % str(t+1))\n",
    "        print('------')\n",
    "        print(f\"Avg Train loss: {avg_train_loss:>8f} \\n\")\n",
    "        print(f\"Avg Train loss w/ eval: {avg_train_loss_nbn:>8f} \\n\")\n",
    "        print(f\"Avg Validation loss: {avg_valid_loss:>8f} \\n\")\n",
    "        print(f\"Avg Test loss: {avg_test_loss:>8f} \\n\")\n",
    "    \n",
    "    train_loss_array[t] = avg_train_loss\n",
    "    valid_loss_array[t] = avg_valid_loss\n",
    "    test_loss_array[t] = avg_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e63df1",
   "metadata": {},
   "source": [
    "## Plot batch-averaged MSE versus epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.plot(train_loss_array, label='Train Loss')\n",
    "plt.plot(valid_loss_array, label='Valid. Loss')\n",
    "plt.plot(test_loss_array, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Batch-Avg MSE Error')\n",
    "plt.legend()\n",
    "#plt.savefig('gnss_fixed_split_s100.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d94ba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Output results for plotting\n",
    "\n",
    "Use model to predict test, validiation, and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return intermediate layer output\n",
    "# See https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # important to disable dropout layers\n",
    "with torch.no_grad():\n",
    "    pred_test = model(test_x)\n",
    "    pred_train = model(train_x)\n",
    "    pred_valid = model(valid_x)\n",
    "    print(loss_func(pred_test,test_y).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09335ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "model.eval() # important to disable dropout/batchnorm layers\n",
    "with torch.no_grad():\n",
    "    h1 = model.relu.register_forward_hook(get_activation('test'))\n",
    "    pred_test = model(test_x)\n",
    "    h1.remove()\n",
    "    h2 = model.relu.register_forward_hook(get_activation('train'))\n",
    "    pred_train = model(train_x)\n",
    "    h2.remove()\n",
    "    h3 = model.relu.register_forward_hook(get_activation('valid'))\n",
    "    pred_valid = model(valid_x)\n",
    "    h3.remove()\n",
    "    print(loss_func(pred_test,test_y).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 160\n",
    "plt.figure(figsize = (24,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(pred_test.detach().numpy()[r,0,:], label = 'Predicted')\n",
    "plt.plot(target_ts[r,0,:], label = 'True')\n",
    "plt.legend()\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(pred_test.detach().numpy()[r,1,:])\n",
    "plt.plot(target_ts[r,1,:])\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(pred_test.detach().numpy()[r,2,:])\n",
    "plt.plot(target_ts[r,2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c25755",
   "metadata": {},
   "source": [
    "#### Output results as .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_test_400_rnn_1l.npy'), pred_test.detach().numpy())\n",
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_train_400_rnn_1l.npy'), pred_train.detach().numpy())\n",
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_valid_400_rnn_1l.npy'), pred_valid.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_test_ts_400_rnn_1l.npy'), activations['test'].detach().numpy())\n",
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_train_ts_400_rnn_1l.npy'), activations['train'].detach().numpy())\n",
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_valid_ts_400_rnn_1l.npy'), activations['valid'].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e98ab7",
   "metadata": {},
   "source": [
    "#### Or alternatively output as a .csv file if you wish to use MATLAB to plot results instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(npyd,'fq_conv1d_wts_test_300.csv'),pred_test.detach().numpy(), delimiter=',')\n",
    "np.savetxt(os.path.join(npyd,'fq_conv1d_wts_train_300.csv'),pred_train.detach().numpy(), delimiter=',')\n",
    "np.savetxt(os.path.join(npyd,'fq_conv1d_wts_valid_300.csv'),pred_valid.detach().numpy(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b477057",
   "metadata": {},
   "source": [
    "# Output the model\n",
    "See https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html for more details such as loading saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights and structure\n",
    "torch.save(model, 'siftconv1d_model.pth')\n",
    "\n",
    "# Save ONLY the model weights\n",
    "torch.save(model.state_dict(), 'siftconv1d_model_wts.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374fd8ac",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d52177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the output with weights and structure\n",
    "model_st = torch.load('siftconv1d_model.pth')\n",
    "model_st.eval()\n",
    "\n",
    "# Compare model prediction from above with prediction from the loaded model\n",
    "# We expect the loss to be 0 if the model was saved and loaded correctly\n",
    "print(loss_func(model_st(test_x),pred_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96144df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the output with ONLY weights\n",
    "model_wt = sconv.Conv1DNN(3, 31).to(device)\n",
    "model_wt.load_state_dict(torch.load('siftconv1d_model_wts.pth'))\n",
    "model_wt.eval()\n",
    "\n",
    "# Compare model prediction from above with prediction from the loaded model\n",
    "# We expect the loss to be 0 if the model was saved and loaded correctly\n",
    "print(loss_func(model_wt(test_x),pred_test).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
