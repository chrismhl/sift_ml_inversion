{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db73f87",
   "metadata": {},
   "source": [
    "# Train and Test 1D Convolutional Neural Network for GNSS\n",
    "\n",
    "Author: Christopher Liu, 9/26/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sift_conv1dnet as sconv\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be464f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ac3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time window\n",
    "\n",
    "# Load fq data\n",
    "npyd = 'npy'\n",
    "eta = np.load(os.path.join(npyd,'gnss_eta_z.npy'))\n",
    "\n",
    "# Load inversions\n",
    "fq_wts = np.load(os.path.join(npyd,'fq_yong_inv_best.npy'))\n",
    "\n",
    "# Split into train, validation,  and test sets\n",
    "inddir = 'indices'\n",
    "\n",
    "train_ind = np.loadtxt(os.path.join(inddir,'fq_dart_train_index.txt')).astype(int)\n",
    "train_runs= np.loadtxt(os.path.join(inddir,'fq_dart_train_runs.txt')).astype(int)\n",
    "\n",
    "test_ind = np.loadtxt(os.path.join(inddir,'fq_dart_test_index.txt')).astype(int)\n",
    "test_runs= np.loadtxt(os.path.join(inddir,'fq_dart_test_runs.txt')).astype(int)\n",
    "\n",
    "valid_ind = np.loadtxt(os.path.join(inddir,'fq_dart_valid_index.txt')).astype(int)\n",
    "valid_runs= np.loadtxt(os.path.join(inddir,'fq_dart_valid_runs.txt')).astype(int)\n",
    "\n",
    "eta_tr = eta[train_runs, :, :]\n",
    "target_tr = fq_wts[train_ind,:]\n",
    "\n",
    "eta_ts = eta[test_runs, :, :]\n",
    "target_ts = fq_wts[test_ind,:]\n",
    "\n",
    "eta_v = eta[valid_runs, :, :]\n",
    "target_v = fq_wts[valid_ind,:]\n",
    "\n",
    "# Convert to tensors. Will need to redo if i want to keep track of run numbers...\n",
    "\n",
    "batch = 20\n",
    "shuf = False\n",
    "\n",
    "train_x = torch.Tensor(eta_tr)\n",
    "train_y = torch.Tensor(target_tr)\n",
    "\n",
    "test_x = torch.Tensor(eta_ts)\n",
    "test_y = torch.Tensor(target_ts)\n",
    "\n",
    "valid_x = torch.Tensor(eta_v)\n",
    "valid_y = torch.Tensor(target_v)\n",
    "\n",
    "# Using the pytorch dataloader\n",
    "train_dataset = TensorDataset(train_x,train_y)\n",
    "test_dataset = TensorDataset(test_x,test_y)\n",
    "valid_dataset = TensorDataset(valid_x,valid_y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch, shuffle = shuf, drop_last= True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch, shuffle = shuf, drop_last= True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch, shuffle = shuf, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    plt.figure(1,figsize=(12,6))\n",
    "    for r in np.arange(62):\n",
    "        plt.plot(np.arange(512), eta_ts[100,r,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556515f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8712e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(dataloader, model, loss_fn):\n",
    "    size = len(dataloader) # number of batches\n",
    "    valid_model = model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = valid_model(X)\n",
    "            \n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "    valid_loss /= size\n",
    "    \n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Set random seed\n",
    "torch.random.manual_seed(100)\n",
    "\n",
    "# Specify model, loss function, and optimizer.\n",
    "nsources = 31 # Number of unit sources used in inversion\n",
    "model = sconv.Conv1DNN_GNSS(62, nsources).to(device)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "nbatches = len(train_dataloader)\n",
    "train_loss_array = np.zeros(epochs)\n",
    "test_loss_array = np.zeros(epochs)\n",
    "valid_loss_array = np.zeros(epochs)\n",
    "\n",
    "for t in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_func(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of training loss\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Calculating the batch-averaged loss\n",
    "    avg_train_loss = train_loss/nbatches\n",
    "    avg_train_loss_nbn = valid(train_dataloader, model, loss_func)\n",
    "    avg_valid_loss = valid(valid_dataloader, model, loss_func)\n",
    "    avg_test_loss = valid(test_dataloader, model, loss_func)\n",
    "    model.train(True) #Do i need this?\n",
    "        \n",
    "    # every 50 epochs, print test error. Adjust print frequency \n",
    "    # depending on epoch size\n",
    "    if (t+1) % 25 == 0:\n",
    "        print('Epoch: %s' % str(t+1))\n",
    "        print('------')\n",
    "        print(f\"Avg Train loss: {avg_train_loss:>8f} \\n\")\n",
    "        print(f\"Avg Train loss w/ eval: {avg_train_loss_nbn:>8f} \\n\")\n",
    "        print(f\"Avg Validation loss: {avg_valid_loss:>8f} \\n\")\n",
    "        print(f\"Avg Test loss: {avg_test_loss:>8f} \\n\")\n",
    "    \n",
    "    train_loss_array[t] = avg_train_loss\n",
    "    valid_loss_array[t] = avg_valid_loss\n",
    "    test_loss_array[t] = avg_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de65a4b",
   "metadata": {},
   "source": [
    "## Plot batch-averaged MSE versus epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.plot(train_loss_array, label='Train Loss')\n",
    "plt.plot(valid_loss_array, label='Valid. Loss')\n",
    "plt.plot(test_loss_array, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Batch-Avg MSE Error')\n",
    "plt.legend()\n",
    "#plt.savefig('gnss_fixed_split_s100.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e188be6",
   "metadata": {},
   "source": [
    "## Output results for plotting\n",
    "\n",
    "Use model to predict test, validiation, and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # important to disable dropout/batchnorm layers\n",
    "with torch.no_grad():\n",
    "    pred_test = model(test_x)\n",
    "    pred_train = model(train_x)\n",
    "    pred_valid = model(valid_x)\n",
    "    print(loss_func(pred_test,test_y).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 800\n",
    "pred_train.detach().numpy()[r:r+20,:] - target_tr[r:r+20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e540c2",
   "metadata": {},
   "source": [
    "#### Output results as .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0451344",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_test_180.npy'), pred_test.detach().numpy())\n",
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_train_180.npy'), pred_train.detach().numpy())\n",
    "np.save(os.path.join(npyd,'fq_conv1d_gnss_wts_valid_180.npy'), pred_valid.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6c188",
   "metadata": {},
   "source": [
    "#### Or alternatively output as a .csv file if you wish to use MATLAB to plot results instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(npyd,'fq_conv1d_wts_test_300.csv'),pred_test.detach().numpy(), delimiter=',')\n",
    "np.savetxt(os.path.join(npyd,'fq_conv1d_wts_train_300.csv'),pred_train.detach().numpy(), delimiter=',')\n",
    "np.savetxt(os.path.join(npyd,'fq_conv1d_wts_valid_300.csv'),pred_valid.detach().numpy(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edb9d1",
   "metadata": {},
   "source": [
    "# Output the model\n",
    "See https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html for more details such as loading saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights and structure\n",
    "torch.save(model, 'siftconv1d_model.pth')\n",
    "\n",
    "# Save ONLY the model weights\n",
    "torch.save(model.state_dict(), 'siftconv1d_model_wts.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd7b10",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the output with weights and structure\n",
    "model_st = torch.load('siftconv1d_model.pth')\n",
    "model_st.eval()\n",
    "\n",
    "# Compare model prediction from above with prediction from the loaded model\n",
    "# We expect the loss to be 0 if the model was saved and loaded correctly\n",
    "print(loss_func(model_st(test_x),pred_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the output with ONLY weights\n",
    "model_wt = sconv.Conv1DNN(3, 31).to(device)\n",
    "model_wt.load_state_dict(torch.load('siftconv1d_model_wts.pth'))\n",
    "model_wt.eval()\n",
    "\n",
    "# Compare model prediction from above with prediction from the loaded model\n",
    "# We expect the loss to be 0 if the model was saved and loaded correctly\n",
    "print(loss_func(model_wt(test_x),pred_test).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
